---
title: "p8105_hw5_dx2262"
output: github_document
---


Load packages.
```{r}
library(tidyverse)
library(broom)
```

## Problem 2

```{r}
sim_results_df <- 
  expand_grid(
    mu = 0:6, 
    iter = 1:5000
  ) %>%
  mutate(
    x = map(mu, ~ rnorm(30, mean = .x, sd = 5)),
    ttest = map(x, ~ t.test(.x, mu = 0)),
    tidy = map(ttest, tidy)
  ) %>%
  unnest(tidy) %>%
  select(
    mu,
    iter,
    estimate, 
    p_value = p.value
  )

```


Make plots.

```{r fig.width=12, fig.height=6, dpi=300}
sim_results_df %>%
  group_by(mu) %>%
  summarize(power = mean(p_value < 0.05)) %>% 
  ggplot(aes(x = mu, y = power)) +
  geom_point() +
  geom_line() +
  labs(
    x = "True mean",
    y = "Power",
    title = "Empirical Power Curve for One-Sample t-test"
  ) +
  theme_minimal()
```

The farther mu is from 0 (effect size grows), the more often the test correctly rejects the null.


```{r}
est_summary <- 
  sim_results_df %>%
  group_by(mu) %>%
  summarize(
    mean_est = mean(estimate),
    mean_est_rejected = mean(estimate[p_value < 0.05]),
    .groups = "drop"
  )
```

```{r fig.width=12, fig.height=6, dpi=300}
est_summary %>% 
  ggplot(aes(x = mu, y = mean_est)) +
  geom_point() +
  geom_line() +
  labs(
    x = "True mean",
    y = "Average estimate of mu_hat",
    title = "All Samples"
  ) +
  theme_minimal()
```

```{r fig.width=12, fig.height=6, dpi=300}
est_summary %>% 
  ggplot(aes(x = mu, y = mean_est_rejected)) +
  geom_point() +
  geom_line() +
  labs(
    x = "True mean",
    y = "Average estimate of mu_hat",
    title = "Rejected Samples"
  ) +
  theme_minimal()
```

The sample average of mu_hat across tests for which the null is rejected does not equal to the true value of mu when mu is small. This is because we have conditioned on having rejected null, selecting only samples whose means were far enough from 0 to cross the significance threshold. This artificially inflates the average estimate.



## Problem 3

```{r}
homicide_data <- 
  read_csv("data/homicide-data.csv") %>% 
  janitor::clean_names() %>% 
  drop_na()
```


Create city_state variable.

```{r}
homicide_data <- 
  homicide_data %>% 
  mutate(
    city_state = str_c(city, state, sep = ",")
  )
```


Total number of homicides, unsolved homicides.

```{r}
homicide_data %>% 
  group_by(city_state) %>% 
  summarize(
    total_homicides = n(),
    unsolved_homicides = sum(disposition %in% c("Closed without arrest", "Open/No arrest"))
  )
```


Unsolved homicides in the city of Baltimore, MD.

```{r}
balt <- 
  homicide_data %>% 
  filter(city_state == "Baltimore,MD") %>% 
  summarize(
    total = n(),
    unsolved = sum(disposition %in% c("Closed without arrest", "Open/No arrest"))
  )

pt <- prop.test(pull(balt, unsolved), pull(balt,total))
pt_tidy <- tidy(pt)

pull(pt_tidy, estimate)
pull(pt_tidy, conf.low)
pull(pt_tidy, conf.high)

```

Each of the cities in the dataset.

```{r}
city_results <- 
  homicide_data %>%
  group_by(city_state) %>%
  summarize(
    total = n(),
    unsolved = sum(disposition %in% c("Closed without arrest", "Open/No arrest")),
    .groups = "drop"
  ) %>%
  mutate(
    prop_test = map2(unsolved, total, ~prop.test(.x, .y))
  ) %>%
  mutate(
    prop_tidy = map(prop_test, tidy)
  ) %>%
  unnest(prop_tidy) %>%
  select(
    city_state,
    estimate,
    conf.low,
    conf.high
  )

city_results
```


Create a plot.

```{r fig.width=12, fig.height=8, dpi=300}
city_results %>%
  arrange(estimate) %>%
  mutate(
    city_state = factor(city_state, levels = city_state)
  ) %>%
  ggplot(aes(x = city_state, y = estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.2) +
  coord_flip() + 
  labs(
    x = "City",
    y = "Proportion of Unsolved Homicides",
    title = "Estimated Proportion of Unsolved Homicides by City"
  ) +
  theme_minimal()
```












